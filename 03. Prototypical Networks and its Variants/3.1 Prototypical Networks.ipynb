{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Prototypical Networks"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Prototypical networks are yet another simple, efficient and most popularly used few shot learning algorithm. Like siamese networks, it tries to learn the metric space to perform classification. The basic idea of the prototypical network is to create a prototypical representation of each class and classify a query point (new point) based on the distance between the class prototype and the query point.\n",
    "\n",
    "Let us say we have a support set comprising images of lion, elephant, and dog as shown below. "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "프로토타입 네트워크는 단순하고 효율적이며 가장 널리 사용되는 샷 학습 알고리즘이다. 샴 네트워크와 마찬가지로, 분류를 수행하기 위해 거리 공간을 학습한다. 프로토타입 네트워크의 기본 아이디어는 각 클래스의 프로토타입 표현을 만들어 클래스 프로토타입과 쿼리 포인트 사이의 거리를 기준으로 쿼리 포인트(새로운 포인트)를 분류하는 것이다."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "![title](Images/1.png)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "So we have three classes {lion, elephant, dog}. Now we need to create a prototypical representation for each of these three class. How can we build the prototype of these three classes? First, we will learn the embeddings of each data point using some embedding function. The embedding function  $f_{\\phi}()$  can be any function which can be used to extract features. Since our input is an image we can use the convolutional network as our embedding function which will extract features from the input image.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "세 가지 클래스{lion, elephant, dog}를 가지고 있다. 이제 우리는 이 세 가지 클래스 각각에 대한 프로토타입적 표현을 만들어야 한다. 이 세 가지 클래스의 프로토타입을 어떻게 만들 수 있을까? 먼저, 우리는 각 데이터 포인트의 임베딩에 대해 어떤 임베딩 기능을 사용하여 배울 것이다. 임베딩 함수 𝜙(()는 형상을 추출하는 데 사용할 수 있는 모든 기능이 될 수 있다. 우리의 입력이 이미지이기 때문에 우리는 입력 이미지에서 피처를 추출할 임베딩 기능으로 콘볼루션 네트워크를 사용할 수 있다."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "![title](Images/2.png)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Once we learn the embeddings of each data point, we take the mean embeddings of data points in each class and form the class prototype as shown below. So, a class prototype is basically the mean embeddings of data points in a class. "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "각 데이터 포인트의 임베딩에 대해 학습한 후에는 각 클래스의 데이터 포인트의 평균 임베딩 방식을 취하여 아래와 같이 클래스 프로토타입을 형성한다. 따라서 클래스 프로토타입은 기본적으로 클래스에 데이터 포인트가 포함된 평균값이다."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "![title](Images/3.png)\n",
    "\n",
    "Similarly, when a new data point comes in i.e query point for which we want to predict the label, we will generate the embeddings for this new data point using the same embedding function that we used to create the class prototype that is, we generate the embeddings for our query point using the convolutional network. \n",
    "\n",
    "마찬가지로, 라벨을 예측하고자 하는 쿼리 포인트(query point)에 새로운 데이터 포인트가 들어오면, 클래스 프로토타입을 만들 때 사용한 것과 동일한 내장 함수를 사용하여 이 새로운 데이터 포인트에 대한 임베딩을 생성할 것이다. 즉, 우리는 콘볼루션 네트워크를 사용하여 쿼리 포인트에 대한 임베딩을 생성한다.\n",
    "\n",
    "![title](Images/4.png)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Once we have the embedding for our query point, we compare the distance between class prototype and query point embeddings to find which class the query point belongs to. We can use Euclidean distance as a distance measure for finding the distance between the class prototype and query points embeddings as shown here:"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "우리의 쿼리 포인트에 임베딩이 되면, 우리는 클래스 프로토타입과 쿼리 포인트 임베딩 사이의 거리를 비교하여 쿼리 포인트가 어느 클래스에 속하는지 찾는다. 다음과 같이 클래스 프로토타입과 쿼리 포인트 사이의 거리를 찾기 위한 거리 측정으로 유클리드 거리를 사용할 수 있다."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "![title](Images/5.png)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "After finding the distance between the class prototype and query point embeddings, we apply softmax to this distance and get the probabilities. Since we have three classes that is, lion, elephant, and dog. We will get three probabilities. So the class which has high probability will be the class of our query point.\n",
    "\n",
    "Since we want our network to learn from few data points that is since we want to perform few shot learning, we train our network in the same way. So we use episodic training that is, for each episode, we randomly sample a few data points from each of the class in our dataset and we call that as support set and we train the network using only the support set instead of the whole dataset. Similarly, we randomly sample a point from the dataset as a query point and try to predict its class. So in this way, our network learns how to learn from the smaller data points.\n",
    "\n",
    "The overall flow of the prototypical network is shown in the following diagram. As you can see, first we will generate the embeddings for all the data points in our support set and build the class prototype by taking the mean embeddings of data points in a class. We also generate the embeddings for our query point. Then we compute the distance between class prototype and query point embeddings. We use Euclidean distance as a distance measure. Then we apply softmax to this distance and get the probabilities. As you can see in the following figure since our query point is a lion, the probability for lion is high which is 0.9:"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "클래스 프로토타입과 쿼리 포인트 임베딩 사이의 거리를 찾은 후, 소프트맥스를 이 거리에 적용하여 확률을 얻는다. 사자, 코끼리, 개 이렇게 3개의 클래스 있기 때문에. 우리는 세 가지 확률을 얻을 것이다. 그래서 확률이 높은 클래스는 우리의 쿼리 포인트 클래스가 될 것이다."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "![title](Images/6.png)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Prototypical networks are not only used for one shot/few shot learning, but it is also used in zero-shot learning. Consider the case where you have no data points per each class but you have the meta information containing a high-level description of each class. So in those cases, we learn the embeddings of meta information of each class to form the class prototype and then perform classification with the class prototype."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "프로토타입 네트워크는 원샷/few 샷 학습에 사용될 뿐만 아니라 제로샷 학습에도 사용된다. 각 클래스당 데이터 포인트가 없으나 각 클래스에 대한 높은 수준의 설명을 포함하는 메타 데이터가 있는 경우에 고려해 보라. 그 경우, 우리는 클래스 프로토타입을 형성하고 나서 클래스 프로토타입으로 분류를 수행하기 위해 각 클래스의 메타정보 임베딩을 학습한다."
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
