{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Relation Networks in One-Shot Learning"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# One-shot ëŸ¬ë‹ ì—ì„œì˜ ê´€ê³„ ë„¤íŠ¸ì›Œí¬"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Relation network consists of two important functions: embedding function denoted by $f_{\\varphi}$  and the relation function denoted by $g_{\\phi}$.  The embedding function is used for extracting the features from the input. If our input is an image, then we can use a convolutional network as our embedding function which will give us the feature vectors/embeddings of an image. If our input is a text, then we can use LSTM networks for getting the embeddings of the text. \n",
    "\n",
    "As we know in one shot learning, we will have only a single example per class, let us say our support set contains three classes with one example per each class.  As shown in the below figure, we have support set containing three classes {lion, elephant, dog}"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "ê´€ê³„ ë„¤íŠ¸ì›Œí¬ëŠ” 2ê°€ì§€ ì¤‘ìš”í•œ ê¸°ëŠ¥ìœ¼ë¡œ êµ¬ì„±ëœë‹¤: ğ‘“ì— ì˜í•´ í‘œì‹œëœ ë‚´ì¥ ê¸°ëŠ¥ê³¼ ğ‘”ì— ì˜í•´ í‘œì‹œëœ ê´€ê³„ ê¸°ëŠ¥ì´ë‹¤.\n",
    "ì„ë² ë”© í•¨ìˆ˜ëŠ” ì…ë ¥ì—ì„œ í”¼ì²˜ë¥¼ ì¶”ì¶œí•˜ëŠ” ë° ì‚¬ìš©ëœë‹¤.\n",
    "ë§Œì•½ ìš°ë¦¬ì˜ ì…ë ¥ì´ ì´ë¯¸ì§€ë¼ë©´, ìš°ë¦¬ëŠ” convolutional networkë¥¼ ì´ë¯¸ì§€ì˜ íŠ¹ì§• ë²¡í„°/ì„ë² ë”© ê¸°ëŠ¥ì„ ì œê³µí•˜ëŠ” ë‚´ì¥ ê¸°ëŠ¥ìœ¼ë¡œ ì‚¬ìš©í•  ìˆ˜ ìˆë‹¤.\n",
    "ë§Œì•½ ìš°ë¦¬ì˜ ì…ë ¥ì´ í…ìŠ¤íŠ¸ë¼ë©´, ìš°ë¦¬ëŠ” í…ìŠ¤íŠ¸ì˜ ì„ë² ë”©ì— LSTM ë„¤íŠ¸ì›Œí¬ë¥¼ ì‚¬ìš©í•  ìˆ˜ ìˆë‹¤.\n",
    "\n",
    "ìš°ë¦¬ê°€ ì›ìƒ· í•™ìŠµì—ì„œ ì•Œê³  ìˆë“¯ì´, ìš°ë¦¬ëŠ” í´ë˜ìŠ¤ë‹¹ í•˜ë‚˜ì˜ ì˜ˆë§Œ ê°€ì§ˆ ê²ƒì´ë‹¤. ìš°ë¦¬ì˜ support ì„¸íŠ¸ì— ê° í´ë˜ìŠ¤ë‹¹ í•˜ë‚˜ì˜ ì˜ˆì‹œê°€ ìˆëŠ” ì„¸ ê°œì˜ í´ë˜ìŠ¤ê°€ í¬í•¨ë˜ì–´ ìˆë‹¤ê³  í•˜ì. ì•„ë˜ ê·¸ë¦¼ê³¼ ê°™ì´, ìš°ë¦¬ëŠ” ì„¸ ê°€ì§€ í´ë˜ìŠ¤ë¥¼ í¬í•¨í•˜ëŠ” support ì„¸íŠ¸ë¥¼ ê°€ì§€ê³  ìˆë‹¤."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    " - ğ‘“ì— ì˜í•´ í‘œì‹œëœ ë‚´ì¥ ê¸°ëŠ¥\n",
    " - ğ‘”ì— ì˜í•´ í‘œì‹œëœ ê´€ê³„ ê¸°ëŠ¥"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "![title](Images/1.png)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "And let us say we have a query image $x_j$ as shown in the below figure and we want to predict the class of this query image. "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "ê·¸ë¦¬ê³  ì•„ë˜ ê°•ì•„ì§€ ê·¸ë¦¼ê³¼ ê°™ì´ query ì´ë¯¸ì§€ ğ‘¥ğ‘—ê°€ ìˆìœ¼ë©° ì´ query ì´ë¯¸ì§€ì˜ í´ë˜ìŠ¤ë¥¼ ì˜ˆì¸¡í•˜ê³  ì‹¶ë‹¤ê³  í•˜ì."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "![title](Images/2.png)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "First, we take each image $x_i$ from the support set and pass it to the embedding function $f_{\\varphi}(x_i)$ for extracting the features. Since our support set has images, we can use convolutional network as our embedding function for learning the embeddings. The embedding function will give us the feature vector of each of the data point in the support set.  Similarly, we will learn the embeddings of our query image $x_j$ by passing it to the embedding function $f_{\\varphi}(x_j)$."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "support ì„¸íŠ¸ë¡œë¶€í„° ê° ì´ë¯¸ì§€ğ‘¥ğ‘–ë¥¼ ì„ë² ë”© í•¨ìˆ˜ ğ‘“ğœ‘(ğ‘¥ğ‘–)ë¡œ ì „ë‹¬í•˜ì—¬ íŠ¹ì§• í”¼ì²˜ë¥¼ ì¶”ì¶œí•œë‹¤. support ì„¸íŠ¸ì—ëŠ” ì´ë¯¸ì§€ê°€ ìˆê¸° ë•Œë¬¸ì— ì„ë² ë”© í•™ìŠµì„ ìœ„í•œ ì½˜ë³¼ë£¨ì…˜ ë„¤íŠ¸ì›Œí¬ë¥¼ ì‚¬ìš©í•  ìˆ˜ ìˆë‹¤. ì„ë² ë”© í•¨ìˆ˜ëŠ” support ì„¸íŠ¸ì— ìˆëŠ” ê° ë°ì´í„° í¬ì¸íŠ¸ì˜ íŠ¹ì§• ë²¡í„°ë¥¼ ìš°ë¦¬ì—ê²Œ ì œê³µí•  ê²ƒì´ë‹¤. ë§ˆì°¬ê°€ì§€ë¡œ ìš°ë¦¬ì˜ query ì´ë¯¸ì§€ ğ‘¥ğ‘—ì˜ ì„ë² ë”©ë„ ì„ë² ë”©í•¨ìˆ˜ ğ‘“ğœ‘(ğ‘¥ğ‘—)ì— ì „ë‹¬í•˜ì—¬ í•™ìŠµí•  ê²ƒì´ë‹¤."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "So, once we have the feature vectors of the support set $f_{\\varphi}(x_i)$ and query set $f_{\\varphi}(x_j)$. We combine them using some operator $Z$. Here $Z$ can be any combination operator, we use concatenation as an operator for combining the feature vectors of support and query set. \n",
    "\n",
    "$Z(f_{\\varphi}(x_i), f_{\\varphi}(x_j)) $"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "support ì„¸íŠ¸ ğ‘¥ğ‘–ì™€ query ì„¸íŠ¸ ğ‘¥ğ‘—ì˜ íŠ¹ì§• ë²¡í„°ë¥¼ ê°€ì§€ê³  ìˆë‹¤. ğ‘ ì˜¤í¼ë ˆì´í„°ë¥¼ í†µí•´ ì¡°í•©ì„ ìˆ˜í–‰í•œë‹¤. ì—¬ê¸°ì„œ ğ‘ì€ ì–´ë–¤ ì¡°í•© ì—°ì‚°ìê°€ ë  ìˆ˜ ìˆìœ¼ë©°, ìš°ë¦¬ëŠ” support ë° query ì„¸íŠ¸ì˜ íŠ¹ì§• ë²¡í„°ë¥¼ ê²°í•©í•˜ê¸° ìœ„í•œ ì—°ì‚°ìë¡œì„œ ê²°í•©ì„ ì‚¬ìš©í•œë‹¤.\n",
    "`ğ‘(ğ‘“ğœ‘(ğ‘¥ğ‘–),ğ‘“ğœ‘(ğ‘¥ğ‘—))`"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "As shown in the below figure we will combine the feature vectors of the support set $f_{\\varphi}(x_i)$   and query set $f_{\\varphi}(x_j)$. But what is the use of combining like this? It will help us to understand how the feature vector of an image in the support set is related to the feature vector of a query image. \n",
    "\n",
    "In our example, it will help us to understand how the feature vector of a lion is related to the feature vector of a query image, how the feature vector of an elephant is related to the feature vector of query image and how the feature vector of dog is related to the feature vector of query image. "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "ì•„ë˜ì˜ ê·¸ë¦¼ê³¼ ê°™ì´ ìš°ë¦¬ëŠ” support ì„¸íŠ¸ ğ‘“ğœ‘(ğ‘¥ğ‘–) ì™€ query ì„¸íŠ¸ ğ‘“ğœ‘(ğ‘¥ğ‘—)ì˜ íŠ¹ì§• ë²¡í„°ë¥¼ ê²°í•©í•  ê²ƒì´ë‹¤.\n",
    "\n",
    "ê·¸ëŸ°ë° ì´ë ‡ê²Œ í•©ì¹˜ë©´ ë¬´ìŠ¨ ì†Œìš©ì´ ìˆì„ê¹Œ? support ì„¸íŠ¸ì— ìˆëŠ” ì´ë¯¸ì§€ì˜ íŠ¹ì§• ë²¡í„°ê°€ query ì´ë¯¸ì§€ì˜ íŠ¹ì§• ë²¡í„°ì™€ ì–´ë–»ê²Œ ê´€ë ¨ë˜ì–´ ìˆëŠ”ì§€ ì´í•´í•˜ëŠ” ë° ë„ì›€ì´ ë  ê²ƒì´ë‹¤.\n",
    "\n",
    "ë³¸ ì˜ˆì—ì„œëŠ” ì‚¬ìì˜ íŠ¹ì§• ë²¡í„°ê°€ query ì´ë¯¸ì§€ì˜ íŠ¹ì§• ë²¡í„°ì™€ ì–´ë–»ê²Œ ê´€ë ¨ë˜ëŠ”ì§€, \n",
    "ì½”ë¼ë¦¬ì˜ íŠ¹ì§• ë²¡í„°ê°€ query ì´ë¯¸ì§€ì˜ íŠ¹ì§• ë²¡í„°ì™€ ì–´ë–»ê²Œ ê´€ë ¨ë˜ëŠ”ì§€, \n",
    "ê°œì˜ íŠ¹ì§• ë²¡í„°ê°€ query ì´ë¯¸ì§€ì˜ íŠ¹ì§• ë²¡í„°ì™€ ì–´ë–»ê²Œ ê´€ë ¨ë˜ëŠ”ì§€ ì´í•´í•˜ëŠ” ë° ë„ì›€ì´ ë  ê²ƒì´ë‹¤."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "![title](Images/3.png)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "But how can we measure this relatedness? So that is why we use a relation function $g_{\\phi}$. We pass this combined feature vectors to the relation function which will generate the relation score ranging from 0 to 1 representing the similarity between samples in the support set $x_i$ and samples in the query set $x_j$."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "ê·¸ëŸ¬ë‚˜ ì´ëŸ¬í•œ ê´€ë ¨ì„±ì„ ì–´ë–»ê²Œ ì¸¡ì •í•  ìˆ˜ ìˆì„ê¹Œ? ê·¸ë˜ì„œ ê´€ê³„ í•¨ìˆ˜ ğ‘”ğœ™ë¥¼ ì‚¬ìš©í•˜ëŠ” ê²ƒì´ë‹¤. ì´ ê²°í•©ëœ íŠ¹ì§• ë²¡í„°ë¥¼ support ì„¸íŠ¸ ğ‘¥ğ‘–ì˜ í‘œë³¸ê³¼ query ì„¸íŠ¸ ğ‘¥ğ‘—ì˜ í‘œë³¸ ì‚¬ì´ì˜ ìœ ì‚¬ì„±ì„ ë‚˜íƒ€ë‚´ëŠ” 0ë¶€í„° 1ê¹Œì§€ì˜ ê´€ê³„ ìŠ¤ì½”ì–´ë¥¼ ìƒì„±í•˜ëŠ” ê´€ê³„ í•¨ìˆ˜ì— ì „ë‹¬í•œë‹¤."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The below equation shows how we compute relation score $r_{ij}$ in relation network, \n",
    "\n",
    "$r_{ij} = g_{\\phi} ( Z(f_{\\varphi}(x_i), f_{\\varphi}(x_j)))$"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "ì•„ë˜ ë°©ì •ì‹ì€ ê´€ê³„ ë„¤íŠ¸ì›Œí¬ì—ì„œ ê´€ê³„ ìŠ¤ì½”ì–´ë¥¼ ê³„ì‚°í•˜ëŠ” ì‹ì´ë‹¤.\n",
    "$r_{ij} = g_{\\phi} ( Z(f_{\\varphi}(x_i), f_{\\varphi}(x_j)))$"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "where $r_{ij}$  denotes the relation score representing similarity between each of the class in the support set and the query image. Since we have three classes in the support set and one image in the query set, we will have  3 scores indicating how all the three classes in the support set is similar to the query image. "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "ì—¬ê¸°ì„œ $r_{ij}$ëŠ” support ì„¸íŠ¸ì˜ ê° í´ë˜ìŠ¤ì™€ query ì´ë¯¸ì§€ ì‚¬ì´ì˜ ìœ ì‚¬ì„±ì„ ë‚˜íƒ€ë‚´ëŠ” ê´€ê³„ ì ìˆ˜ë¥¼ ë‚˜íƒ€ë‚¸ë‹¤. support ì„¸íŠ¸ì— ì„¸ ê°œì˜ í´ë˜ìŠ¤ê°€ ìˆê³  query ì„¸íŠ¸ì— í•œ ê°œì˜ ì´ë¯¸ì§€ê°€ ìˆìœ¼ë¯€ë¡œ query ì„¸íŠ¸ì— ìˆëŠ” ì„¸ ê°œì˜ í´ë˜ìŠ¤ê°€ ëª¨ë‘ query ì´ë¯¸ì§€ì™€ ì–´ë–»ê²Œ ìœ ì‚¬í•œì§€ ë‚˜íƒ€ë‚´ëŠ” 3ê°œì˜ ì ìˆ˜ê°€ ìˆì„ ê²ƒì´ë‹¤."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The overall representation of relation network in one shot learning setting is shown in the below figure, "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "ì› ìƒ· ëŸ¬ë‹ ì„¸íŒ…ì˜ ê´€ê³„ ë„¤íŠ¸ì›Œí¬ ì „ì²´ì ì¸ í‘œí˜„ì€ ì•„ë˜ ê·¸ë¦¼ì— ë‚˜ì™€ ìˆë‹¤."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "![title](Images/4.png)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "In the next section, we will learn how relation network is used in few shot and zero shot learning system. "
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
