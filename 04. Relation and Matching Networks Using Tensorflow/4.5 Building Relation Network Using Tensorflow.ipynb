{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Building Relation Network Using Tensorflow"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Relation network is pretty simple, right? Now, we will understand relation network better by implementing it in TensorFlow. We will consider a simple binary classification problem and see how can we solve them using a relation network. "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    " 이제 텐서플로우에서 구현하여 관계망을 더 잘 이해할 것이다. 단순한 이항분류 문제를 고려해 관계망을 이용해 어떻게 해결할 수 있는지 살펴보겠다."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "First, we import all the required libraries,"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/usr/local/lib/python3.6/dist-packages/tensorflow/python/framework/dtypes.py:516: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.\n",
      "  _np_qint8 = np.dtype([(\"qint8\", np.int8, 1)])\n",
      "/usr/local/lib/python3.6/dist-packages/tensorflow/python/framework/dtypes.py:517: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.\n",
      "  _np_quint8 = np.dtype([(\"quint8\", np.uint8, 1)])\n",
      "/usr/local/lib/python3.6/dist-packages/tensorflow/python/framework/dtypes.py:518: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.\n",
      "  _np_qint16 = np.dtype([(\"qint16\", np.int16, 1)])\n",
      "/usr/local/lib/python3.6/dist-packages/tensorflow/python/framework/dtypes.py:519: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.\n",
      "  _np_quint16 = np.dtype([(\"quint16\", np.uint16, 1)])\n",
      "/usr/local/lib/python3.6/dist-packages/tensorflow/python/framework/dtypes.py:520: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.\n",
      "  _np_qint32 = np.dtype([(\"qint32\", np.int32, 1)])\n",
      "/usr/local/lib/python3.6/dist-packages/tensorflow/python/framework/dtypes.py:525: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.\n",
      "  np_resource = np.dtype([(\"resource\", np.ubyte, 1)])\n",
      "/usr/local/lib/python3.6/dist-packages/tensorboard/compat/tensorflow_stub/dtypes.py:541: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.\n",
      "  _np_qint8 = np.dtype([(\"qint8\", np.int8, 1)])\n",
      "/usr/local/lib/python3.6/dist-packages/tensorboard/compat/tensorflow_stub/dtypes.py:542: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.\n",
      "  _np_quint8 = np.dtype([(\"quint8\", np.uint8, 1)])\n",
      "/usr/local/lib/python3.6/dist-packages/tensorboard/compat/tensorflow_stub/dtypes.py:543: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.\n",
      "  _np_qint16 = np.dtype([(\"qint16\", np.int16, 1)])\n",
      "/usr/local/lib/python3.6/dist-packages/tensorboard/compat/tensorflow_stub/dtypes.py:544: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.\n",
      "  _np_quint16 = np.dtype([(\"quint16\", np.uint16, 1)])\n",
      "/usr/local/lib/python3.6/dist-packages/tensorboard/compat/tensorflow_stub/dtypes.py:545: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.\n",
      "  _np_qint32 = np.dtype([(\"qint32\", np.int32, 1)])\n",
      "/usr/local/lib/python3.6/dist-packages/tensorboard/compat/tensorflow_stub/dtypes.py:550: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.\n",
      "  np_resource = np.dtype([(\"resource\", np.ubyte, 1)])\n"
     ]
    }
   ],
   "source": [
    "import tensorflow as tf\n",
    "import numpy as np"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Let us say we have two classes in our dataset, we will randomly generate some 1000 data points for each of these classes."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "데이터 집합에 두 개의 클래스가 있다고 가정해봅시다. 각 클래스에 대해 랜덤하게 1000개의 데이터 포인트를 생성해 봅시다."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "classA = np.random.rand(1000,18)\n",
    "\n",
    "ClassB = np.random.rand(1000,18)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Create our dataset by combining both of these classes,"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "두 클래스를 모두 결합하여 데이터셋 생성"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "data = np.vstack([classA, ClassB])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now we will set the label, we assign label 1 for classA and label 0 for classB. "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "클래스 A에는 라벨 1을, 클래스 B에는 라벨 0을 할당하여 라벨을 설정한다."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "label = np.vstack([np.ones((len(classA),1)),np.zeros((len(ClassB),1))])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "So, our dataset will have 2000 records"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(2000, 18)"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(2000, 1)"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "label.shape"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now, we will define the placeholders for our support set $x_i$ and query set $x_j$. "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "$x_i$ $x_j$ 를 담을 수 있는 텐서 변수를 생성한다."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "xi = tf.placeholder(tf.float32, [None, 9])\n",
    "xj = tf.placeholder(tf.float32, [None, 9])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Define the placeholder for label y,"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "라벨 y 를 담을 수 있는 텐서 변수를 생성"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "y = tf.placeholder(tf.float32, [None, 1]) "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now, we will define our embedding function $f_{\\varphi}$()  to learn the embeddings of support set and query set. We will use a normal feedforward network as our embedding function. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "def embedding_function(x):\n",
    "    \n",
    "    weights = tf.Variable(tf.truncated_normal([9,1]))\n",
    "    bias = tf.Variable(tf.truncated_normal([1]))\n",
    "    \n",
    "    a = (tf.nn.xw_plus_b(x,weights,bias))\n",
    "    embeddings = tf.nn.relu(a)\n",
    "    \n",
    "    return embeddings"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Compute the embeddings of our support set i.e $f_{\\varphi}(x_i) $"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "support 세트의 임베딩을 계산한다. i.e $f_{\\varphi}(x_i) $"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "f_xi = embedding_function(xi)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Compute the embeddings of our query set i.e $f_{\\varphi}(x_j)$"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "query 세트의 임베딩을 계산한다. $f_{\\varphi}(x_j)$"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "f_xj = embedding_function(xj)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now that we calculated the embeddings and have the feature vectors, we combine both the support set and query set feature vectors i.e $Z(f_{\\varphi}(x_i), f_{\\varphi}(x_j))$"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "임베딩을 계산하고 피쳐 벡터를 갖게 되었으므로, support 세트와 query 세트 피쳐 벡터를 모두 결합한다. \n",
    "$Z(f_{\\varphi}(x_i), f_{\\varphi}(x_j))$"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "Z = tf.concat([f_xi,f_xj],axis=1)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We define our relation function $g_{\\phi}()$ as three layered neural network with relu activations, "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "우리는 우리의 관계 함수  $g_{\\phi}()$를  ReLU 활성화 함수와 3계층 신경 네트워크로 정의한다."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [],
   "source": [
    "def relation_function(x):\n",
    "    w1 = tf.Variable(tf.truncated_normal([2,3]))\n",
    "    b1 = tf.Variable(tf.truncated_normal([3]))\n",
    "    \n",
    "    w2 = tf.Variable(tf.truncated_normal([3,5]))\n",
    "    b2 = tf.Variable(tf.truncated_normal([5]))\n",
    "    \n",
    "    w3 = tf.Variable(tf.truncated_normal([5,1]))\n",
    "    b3 = tf.Variable(tf.truncated_normal([1]))\n",
    "    \n",
    "    #layer1\n",
    "    z1 = (tf.nn.xw_plus_b(x,w1,b1))\n",
    "    a1 = tf.nn.relu(z1)\n",
    "    \n",
    "    #layer2\n",
    "    z2 = tf.nn.xw_plus_b(a1,w2,b2)\n",
    "    a2 = tf.nn.relu(z2)\n",
    "    \n",
    "    #layer3\n",
    "    z3 = tf.nn.xw_plus_b(a2,w3,b3)\n",
    "\n",
    "    #output\n",
    "    y = tf.nn.sigmoid(z3)\n",
    "    \n",
    "    return y"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We now pass the concatenated feature vectors of support set and query set to the relation function and get the relation scores, "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "support, query 세트의 결합된 특징 벡터를 관계 함수에 전달하여 관계 스코어를 얻는다."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [],
   "source": [
    "relation_scores = relation_function(Z)   # Z = tf.concat([f_xi,f_xj],axis=1)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We define our loss function as mean squared error i.e squared difference between relation scores and actual y value. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {},
   "outputs": [],
   "source": [
    "loss_function = tf.reduce_mean(tf.squared_difference(relation_scores,y))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We can minimize the loss using adam optimizer,"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "손실 함수를 평균 제곱 오차(즉, 관계 점수와 실제 y 값 사이의 제곱 차이)로 정의한다."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {},
   "outputs": [],
   "source": [
    "optimizer = tf.train.AdamOptimizer(0.1)\n",
    "train = optimizer.minimize(loss_function)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now, let's start our tensorflow session"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {},
   "outputs": [],
   "source": [
    "sess = tf.InteractiveSession()\n",
    "sess.run(tf.global_variables_initializer())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now, we randomly sample data points for our support set $x_i$ and query set $x_j$ and train the network, "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Episode 0: loss 0.482 \n",
      "Episode 100: loss 0.250 \n",
      "Episode 200: loss 0.250 \n",
      "Episode 300: loss 0.250 \n",
      "Episode 400: loss 0.250 \n",
      "Episode 500: loss 0.250 \n",
      "Episode 600: loss 0.250 \n",
      "Episode 700: loss 0.250 \n",
      "Episode 800: loss 0.250 \n",
      "Episode 900: loss 0.250 \n"
     ]
    }
   ],
   "source": [
    "for episode in range(1000):\n",
    "    _, loss_value = sess.run([train, loss_function], \n",
    "                             feed_dict={xi:data[:,0:9]+np.random.randn(*np.shape(data[:,0:9]))*0.05,\n",
    "                                        xj:data[:,9:]+np.random.randn(*np.shape(data[:,9:]))*0.05,\n",
    "                                        y:label})\n",
    "    if episode % 100 == 0:\n",
    "        print(\"Episode {}: loss {:.3f} \".format(episode, loss_value))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
